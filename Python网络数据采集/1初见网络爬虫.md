# 第一部分 创建爬虫
----------
# 第一章 初见网络爬虫
## 1.1 网络连接
下面是一个理解浏览器如何获取信息的例子：

Alice有一台网络服务器。Bob有一个台式机正准备连接Alice的服务器。当一台机器想与另一台机器对话时，下面的某个行为将会发生。
1. Bob 的电脑发送一串1和0比特值，表示电路上的高低电压。这些比特构成了一种信 息，包括请求头和消息体。**请求头包含当前 Bob的本地路由器MAC地址和Alice的IP地址**。**消息体包含 Bob 对 Alice 服务器应用的请求**。 
2.  Bob 的本地路由器收到所有 1 和 0 比特值，把它们理解成一个数据包（packet），从 Bob 自己的 MAC 地址“寄到”Alice 的 IP 地址。他的路由器把数据包“盖上”自己的 IP 地址作为“发件”地址，然后通过互联网发出去。
3. Bob 的数据包游历了一些中介服务器，沿着正确的物理/电路路径前进，到了 Alice 的 服务器。
4. Alice 的服务器在她的 IP 地址收到了数据包。 
5. Alice 的服务器读取数据包请求头里的目标端口（通常是网络应用的 80 端口，可以理解 成数据包的“房间号”，IP 地址就是“街道地址”），然后把它传递到对应的应用——网络服务器应用上。 
6. 网络服务器应用从服务器处理器收到一串数据，数据是这样的：
    
   ♦ 这是一个 GET 请求 

   ♦ 请求文件 index.html 
7. 网络服务器应用找到对应的 HTML 文件，把它打包成一个新的数据包发送给 Bob，然 后通过它的本地路由器发出去，用同样的过程回传到 Bob 的机器上。

这样就实现了互联网中的一次数据交换。

但是在这场数据交换中，浏览器完全没有参与。浏览器创建信息的数据包，发送它们，然后把你获 取的数据解释成图像、声音、视频和文字。但许多语言也有实现这样功能的库文件。

python是这样实现的：
```python
from urllib.request import urlopen
html=urlopen(" http://pythonscraping.com/pages/page1.html")
print(html.read())
```
运行之后这将会输出 http://pythonscraping.com/pages/page1.html 这个网页的全部 HTML 代码。更准确地说，这会输出在域名为 http://pythonscraping.com 的服务器上 < 网络应用根地址 >/ pages 文件夹里的 HTML 文件 page1.html 的源代码。
## 1.2 BeautifulSoup



